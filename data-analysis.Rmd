---
title: "Traffic Data Analysis"
output: 
    html_document:
      toc: true
      toc_float: false
      collapsed: false
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(dplyr)
library(knitr)
library(stargazer)
library(MASS)
library(pracma)
library(tidyr)
library(lubridate)
library(XML)
library(pastecs)
```

### Reading and Processing Data

This section is responsible for reading the data and cleaning it.

#### Data Reading

```{r, tidy=TRUE, cache=TRUE}
be2olak.data <- read.csv("all-semi-unique.csv")
names(be2olak.data)
str(be2olak.data)
dim(be2olak.data)
```

***

#### Data Cleaning

The aim of this section:

* Remove not needed columns
* Remove duplicated rows
* Remove NAs

#### Removing not needed columns

By analyzing the distribution of some columns, I found that some of the columns only have one value, so these columns are not needed and should be deleted from the data.

```{r, tidy=TRUE, cache=TRUE}
column_count = sapply(be2olak.data, function(x) length(unique(x)))
be2olak.data <- be2olak.data[, !names(be2olak.data) %in% names(column_count[column_count==1])]
```

Moreover, the 6 columns (rd.stid, rd.hr, rd.mn, rd.rp.fullnm, rd.img, rd.rp.img) are meaningless and want add anything to the data so I will remove them:

```{r, tidy=TRUE, cache=TRUE}
columns.delete = c("rd.stid", "rd.hr", "rd.mn", "rd.rp.fullnm", "rd.img", "rd.rp.img")
```

```{r, tidy=TRUE, cache=TRUE}
be2olak.data <- be2olak.data[, !names(be2olak.data) %in% columns.delete]
```

```{r, tidy=TRUE, cache=TRUE}
stargazer(be2olak.data, type = "text", title = "Descriptive statistics")
```

***

#### Removing Duplicated Rows

Now we need only to keep the unique rows and remove any duplicates. In order to do that, I checked the number of unique rows with respect to more than one combination of columns to get what really affect the data.

```{r, tidy=TRUE, cache=TRUE}
# with respect to comment id
nrow(unique(be2olak.data[c("rd.rp.cmid")]))
# with respect to status id, and comment id
nrow(unique(be2olak.data[c("rd.rp.stid", "rd.rp.cmid")]))
# with respect to road index, status id, and comment id
nrow(unique(be2olak.data[c("rd.ri", "rd.rp.stid", "rd.rp.cmid")]))
```

From the results presented above, the combination of (road index, status id, and comment id) would make the report entry unique.

So now I will remove duplicated rows.

```{r, tidy=TRUE, cache=TRUE}
be2olak.data <- be2olak.data[!duplicated(be2olak.data[,which( colnames(be2olak.data) %in% c("rd.rp.cmid", "rd.rp.stid", "rd.ri") )]),]
```

Checking data summary again after removing the duplicated rows:

```{r, tidy=TRUE, cache=TRUE}
dim(be2olak.data)
stargazer(be2olak.data, type = "text", title = "Bey2ollak Data")
summary(be2olak.data)
str(be2olak.data)
```


***
#### Investigate NAs

First, lets check the proportion of NAs:
```{r, tidy=TRUE, cache=TRUE}
length(be2olak.data[is.na(be2olak.data)])/(ncol(be2olak.data)*nrow(be2olak.data)) 
```

And from the summary results the Nas are there because of 2 columns (rd.rp.stid , rd.rp.rpImg)

So for rd.rp.rpImg, it means that the reporter has uploaded a photo for the road. Otherwise, it means the he/she did not.

So for my analysis, I am not concerned with photo itself, I am only concerned with the uploading action. So I will remove this column after adding one that has "YES" or "NO" representing whether this report has an uploaded photo or not.

```{r, tidy=TRUE, cache=TRUE}
be2olak.data$rp.has.photo <- as.factor(ifelse(is.na(be2olak.data$rd.rp.rpImg), "NO", "YES"))
be2olak.data$rd.rp.rpImg <- NULL
```

So check on the proportion of NAs again

```{r, tidy=TRUE, cache=TRUE}
length(be2olak.data[is.na(be2olak.data)])/(ncol(be2olak.data)*nrow(be2olak.data)) 
```


```{r, tidy=TRUE, cache=TRUE}
dim(be2olak.data)
stargazer(be2olak.data, type = "text", title = "Bey2ollak Data")
summary(be2olak.data)
str(be2olak.data)
```

Now lets get to the other column which is the rd.rp.stid

#### Exploring the NAs of the rd.rp.stid column

Note, here is a function taken from online resource that I will be using in my analysis

```{r, tidy=TRUE, cache=TRUE}
freqfunc <- function(x, n){
  tail(sort(table(unlist(strsplit(as.character(x), ", ")))), n)
}
```

Ok, Let get only the rows where rd.rp.stid is NA

```{r, tidy=TRUE, cache=TRUE}
missing.stid <- be2olak.data[is.na(be2olak.data$rd.rp.stid), c("rd.rp.cm", "rd.nm")]
str(missing.stid)
summary(missing.stid)
ggplot(missing.stid, aes(x = rd.nm, fill = rd.nm)) + geom_bar()
```

checking most of the comments in those reports

```{r, tidy=TRUE, cache=TRUE}
freqfunc(missing.stid$rd.rp.cm, 60)
```


```{r, tidy=TRUE, cache=TRUE}
missing.stid <- missing.stid %>% separate(rd.nm, c("road.main"), extra = "drop", sep = ";", convert = F, remove = F)
missing.stid$road.main <- as.factor(missing.stid$road.main)
#missing.stid$rd.ri <- as.factor(missing.stid$rd.ri)
summary(missing.stid)
#print.data.frame(missing.stid)
ggplot(missing.stid, aes(x=road.main, y=rd.nm)) + geom_jitter()
```

So after analyzing the rows that has stid with NAs so mainly they are highway roads and roads connecting between cities.

Moreover, The comments are mainly about asking about radar and reporting radars or clear statuses.

Those type of roads would need another analysis, but for my analysis I would remove those roads from the original data frame.


```{r, tidy=TRUE, cache=TRUE}

```



```{r, tidy=TRUE, cache=TRUE}
#ri.freq <- table(missing.stid$rd.ri)
#print(ri.freq)
#str(ri.freq)
#barplot(ri.freq, main = "Frequency of roads missing stid")
#func <- missing.stid$rd.ri*100.0/nrow(missing.stid)
#plot(x = missing.stid$rd.ri, y = func)
```



***
***
***

Get the most frequent strings in comments column

```{r, tidy=TRUE, cache=TRUE}
freqfunc <- function(x, n){
  tail(sort(table(unlist(strsplit(as.character(x), ", ")))), n)
}
freqfunc(be2olak.data$rd.rp.cm, 10)
```

***

#### Plotting graphs for the different columns

```{r, tidy=TRUE, cache=TRUE}
status <- be2olak.data$rd.rp.stid
status.freq <- table(status)
#pie(status.freq, radius = 1)
print(status.freq)
str(status.freq)
barplot(status.freq)
```

```{r, tidy=TRUE, cache=TRUE}
hist(status,xlab = "Comment status",10)
```

```{r, tidy=TRUE, cache=TRUE}
stid.nas <- sum(is.na(be2olak.data$rd.rp.stid))
print(stid.nas)
stid.nas/(nrow(be2olak.data)) 
ggplot(be2olak.data) + geom_bar(aes(x=rd.rp.stid), fill="gray")
```

By Montoring Be2ollak website, I was able to find most of those status look like:

* 1 --> :D
* 2 --> :)
* 3 --> :|
* 4 --> :(
* 5 --> :'(
* 6 --> ?
* 7 --> Danger Skull
* 10 --> lamb

However, 8 and 9 were difficult to find in the feed.


```{r, tidy=TRUE, cache=TRUE}
#write.csv(be2olak.data, file = "MyData.csv",row.names=FALSE)
```

***

### Feature Engineering

The crawling date is presented in a way that we could make a use of to get the other columns that might help in viewing relations between columns.

Moreover, it will allow us to get the actual date of report from a user, which in case of "za7ma" reports for example, it will get the actual time of the phenomenon.

So to do this, there are 2 main steps:

* First, is to split the crawl date into week day, month, month day, crawl-date (as hours - minutes - seconds) only.

* Then form a new column representing this a formated crawling date.

* Then get the actual reports date (taking into consideration the difference between EET and UCT).

#### Format Crawl Date in a better way

```{r, tidy=TRUE, cache=TRUE}
new.data <- be2olak.data %>% separate(crawl_date, c("Week_day", "Month", "Month_day", "Crawl_date"), extra = "drop", sep = "[ ]+", convert = TRUE, remove = TRUE) %>% unite(Crawl.time, Week_day, Month, Month_day, Crawl_date, sep = " ", remove = FALSE)
summary(new.data)
str(new.data)
new.data$formated.date <- as.POSIXct(strptime(new.data$Crawl.time, format="%a %b %d %H:%M:%S"))
str(new.data)
summary(new.data)
#new.data$Crawl_date <- as.Date(as.character(new.data$Crawl_date))
#str(new.data)
```

***

#### Get Comment's Actual Time

```{r, tidy=TRUE, cache=TRUE}

# Adding 2 hours to get Egypt's local time instead of UTC
# Remove the duration of the report has been posted presented by rd.rp.hr and rd.rp.mn

new.data$comment.time <- new.data$formated.date + hours(2) - hours(new.data$rd.rp.hr) - minutes(new.data$rd.rp.mn)

str(new.data)
summary(new.data)
glimpse(new.data)
#View(new.data)
```

***

Another thing that could be done related to augmenting the data, is to add a column representing the city of each the road being reported on, whether it is "cairo" or "alex". And this is done in the next section.

#### Add the city for each entry

First, get the ids of the roads in Cairo.

```{r, tidy=TRUE, cache=TRUE}

# Get Cairo Road ids

doc <- htmlParse("http://www.bey2ollak.com/Bey2ollak/Traffic?action=getTraffic&ver=1.0&w=320&h=240&deviceType=10&lang=1&protocol=1&city=0&lang=1")
cairo.roads.id <- sapply(getNodeSet(doc, "//ri"), function(x) as.integer(xmlValue(x)))
length(cairo.roads.id)

```

Then, get the ids of the roads in Alex.

```{r, tidy=TRUE, cache=TRUE}

# Get Alex Road ids

doc <- htmlParse("http://www.bey2ollak.com/Bey2ollak/Traffic?action=getTraffic&ver=1.0&w=320&h=240&deviceType=10&lang=1&protocol=1&city=1&lang=1")
alex.roads.id <- sapply(getNodeSet(doc, "//ri"), function(x) as.integer(xmlValue(x)))
length(alex.roads.id)
```

```{r, tidy=TRUE, cache=TRUE}
length(unique(c(unique(alex.roads.id),unique(cairo.roads.id))))
```


Then, add column representing the city in each row in the dataframe.

```{r, tidy=TRUE, cache=TRUE}
#be2olak.data$city <- as.factor(ifelse(be2olak.data$rd.ri %in% cairo.roads.id, "cairo", "alex"))
#str(be2olak.data)
#levels(be2olak.data$city)
#ggplot(be2olak.data) + geom_bar(aes(x = city), fill = "gray")
```

```{r, tidy=TRUE, cache=TRUE}
be2olak.data$city[(be2olak.data$rd.ri %in% cairo.roads.id)] = "cairo"
be2olak.data$city[(be2olak.data$rd.ri %in% alex.roads.id)] = "alex"
be2olak.data$city <- as.factor(be2olak.data$city)
str(be2olak.data)
summary(be2olak.data$city)
levels(be2olak.data$city)
yarab2 <- unique(be2olak.data$rd.ri[is.na(be2olak.data$city)])
print(yarab2)
length(yarab2)
yarab3 <- unique(be2olak.data$rd.nm[is.na(be2olak.data$city)])
print(yarab3)
yarab3 <- as.character(yarab3)
print(yarab3)
unique(be2olak.data$rd.ri[which(be2olak.data$rd.nm %in% c("Sa7rawy;Alex To Cairo"))])
ggplot(be2olak.data) + geom_bar(aes(x = city), fill = "gray")
```

```{r, tidy=TRUE, cache=TRUE}
#stat.desc(be2olak.data)
#tapply(be2olak.data$rd.rp.stid, be2olak.data$city, mean)
```

***

### Exploring the NAs of the rd.rp.stid column

```{r, tidy=TRUE, cache=TRUE}
missing.stid <- be2olak.data[is.na(be2olak.data$rd.rp.stid), c("rd.rp.cm", "rd.ri", "city", "rd.nm")]
str(missing.stid)
summary(missing.stid)
ggplot(missing.stid) + geom_bar(aes(x = city), fill = "gray")
plot(missing.stid$city, main = "city missing ratio")
ggplot(missing.stid) + geom_bar(aes(x = rd.ri), fill = "red")
hist(missing.stid$rd.ri, xlab = "Comment status", 10)
hist(missing.stid$rd.ri, freq = F, xlab = "Comment status", 40)
freqfunc(missing.stid$rd.rp.cm, 80)
```


```{r, tidy=TRUE, cache=TRUE}
missing.stid <- missing.stid %>% separate(rd.nm, c("MainRoad", "PartOfRoad"), extra = "drop", sep = ";", convert = TRUE, remove = F)
missing.stid$MainRoad <- as.factor(missing.stid$MainRoad)
missing.stid$rd.ri <- as.factor(missing.stid$rd.ri)
summary(missing.stid)
#print.data.frame(missing.stid)
ggplot(missing.stid, aes(x=MainRoad, y=rd.ri)) + geom_tile(aes(fill=city))
```

So after analyzing the rows that has stid with NAs so mainly they are highway roads and roads connecting between cities, so it is inconvenient for say that they do belong to one city according to the direction of the road.

Moreover, The comments are mainly about asking about radar and reporting radars or clear statuses.

Those type of roads would need another analysis, but for my analysis I would remove those roads from the original data frame.

```{r, tidy=TRUE, cache=TRUE}
#ri.freq <- table(missing.stid$rd.ri)
#print(ri.freq)
#str(ri.freq)
#barplot(ri.freq, main = "Frequency of roads missing stid")
#func <- missing.stid$rd.ri*100.0/nrow(missing.stid)
#plot(x = missing.stid$rd.ri, y = func)
```


```{r, tidy=TRUE, cache=TRUE}
#write.csv(missing.stid, file = "MissingDataStid.csv",row.names=FALSE)
```


```{r, tidy=TRUE, cache=TRUE}

```

***
### Hypotheses

Here are some ideas for Hypotheses that could be tried

* [1] The ratio of negative reports in Cairo is much higher than in Alex.
* [2] The ratio of negative reports on Firday is less than any other day in the week.
* [3] In (3otl, 7adsa, khatar), the probabitity of uploading an image in a report is significantly higher than in normal times.
* [4] Leaving the default message of a status is higher than of write customized ones.
* [5] [7:30 am - 9 am] and [2 pm - 4 pm] have higher rate of negative reports than in other times of the day.

***
***
***

CMRQ and STRQ

```{r, tidy=TRUE, cache=TRUE}
strq.cmrq <- be2olak.data[which(be2olak.data$rd.strq == be2olak.data$rd.cmrq),]
nrow(strq.cmrq)
head(strq.cmrq[,c(2:13)])
```

```{r, tidy=TRUE, cache=TRUE}
unique.cmid <- aggregate(rd.rp.stid ~ rd.rp.cmid, be2olak.data, length)
duplicated.cmid <- unique.cmid[ which(unique.cmid$rd.rp.stid > 1), ]
head(duplicated.cmid)
tail(duplicated.cmid)
```


```{r, tidy=TRUE, cache=TRUE}
duplicated.cmid.vector <- rbind(duplicated.cmid$rd.rp.cmid)
#print(duplicated.cmid.vector)
duplicated.rows <- be2olak.data[ which(be2olak.data$rd.rp.cmid %in% duplicated.cmid.vector), ]
nrow(duplicated.rows[!duplicated.rows$rd.rp.nm %in% c("bey2ollakgps"),])
```

From above we reached that duplicated rows are only existing when rd.rp.nm is "be2ollakgps"

```{r, tidy=TRUE, cache=TRUE}
stid10.percentage <- nrow(duplicated.rows[which(duplicated.rows$rd.rp.stid == 10),]) * 100.0/ nrow(duplicated.rows)
print(stid10.percentage)
```



***

```{r, echo=F, eval=F, tidy=TRUE, cache=TRUE}
library(rmarkdown)
render("data-analysis.Rmd")
```
